import torch
from torch.utils.data import DataLoader, RandomSampler, SequentialSampler
from transformer_model import ExploitsModel
from exploits_dataset import ExploitsDataset
from transformers import AdamW,\
                         RobertaConfig,\
                         RobertaForSequenceClassification,\
                         RobertaTokenizer,\
                         get_linear_schedule_with_warmup
                         
from tqdm import tqdm
import numpy as np
import os
import yaml
from sklearn import metrics
import json

class ExploitsModelTrainer:
    def __init__(self, args : dict = None, num_labels : int = 3):
        self.config = RobertaConfig.from_pretrained(args['model_name_or_path'])
        self.config.num_labels = num_labels
        
        self.tokenizer = RobertaTokenizer.from_pretrained(args['tokenizer_name'])
        self.model = RobertaForSequenceClassification.from_pretrained(args['model_name_or_path'], config=self.config)    
        self.model = ExploitsModel(self.model, self.config, self.tokenizer, args)
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        args['device'] = device
        self.model.to(device)
        
        self.train_dataset = ExploitsDataset(self.tokenizer, args, args['train_data_file'])
        
    def train(self, args : dict = None):
        
        train_sampler = RandomSampler(self.train_dataset)
    
        train_dataloader = DataLoader(
            self.train_dataset, 
            sampler=train_sampler,
            batch_size=args['train_batch_size'],
            num_workers=4,
            pin_memory=True
            )
        
        no_decay = ['bias', 'LayerNorm.weight']
        optimizer_grouped_parameters = [
            {'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],
            'weight_decay': args['weight_decay']},
            {'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)], 
             'weight_decay': 0.0}
        ]
        optimizer = AdamW(optimizer_grouped_parameters, 
                          lr=args['learning_rate'], 
                          eps=args['adam_epsilon'])
        max_steps = len(train_dataloader) * args['num_train_epochs']
        scheduler = get_linear_schedule_with_warmup(optimizer, 
                                                    num_warmup_steps=max_steps*0.1,
                                                    num_training_steps=max_steps)
        
        print("***** TRAINING *****")
        print("  Num examples = %d", len(self.train_dataset))
        print("  Num Epochs = %d", args['num_train_epochs'])
        print("  batch size = %d", args['train_batch_size'])
        print("  Total optimization steps = %d", max_steps)
        
        best_acc=0.0
        self.model.zero_grad()
        
        for idx in range(args['num_train_epochs']): 
            bar = tqdm(train_dataloader, total=len(train_dataloader))
            losses=[]
            for step, batch in enumerate(bar):
                inputs = batch[0].to(args['device'])        
                labels = batch[1].to(args['device']) 
                self.model.train()
                loss, logits = self.model(inputs, labels)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), args['max_grad_norm'])
                losses.append(loss.item())
                bar.set_description("epoch {} loss {}".format(idx, round(np.mean(losses), 3)))
                optimizer.step()
                optimizer.zero_grad()
                scheduler.step()

            results = self.evaluate(args)
            for key, value in results.items():
                print("  %s = %s", key, round(value, 4))
                
            if results['eval_acc'] > best_acc:
                best_acc = results['eval_acc']
                print("  " + "*" * 20)  
                print("  Best acc:%s", round(best_acc, 4))
                print("  " + "*" * 20)                          

                checkpoint_prefix = 'checkpoint-best-acc'
                output_dir = os.path.join(args['output_dir'], '{}'.format(checkpoint_prefix))                        
                if not os.path.exists(output_dir):
                    os.makedirs(output_dir)                        
                model_to_save = self.model.module if hasattr(self.model,'module') else self.model
                output_dir = os.path.join(output_dir, '{}'.format('model.bin')) 
                torch.save(model_to_save.state_dict(), output_dir)
                print("Saving model checkpoint to %s", output_dir)
            
    
    def evaluate(self, args : dict = None):
        
        eval_output_dir = args['output_dir']
        eval_dataset = ExploitsDataset(self.tokenizer, args, args['eval_data_file'])
        if not os.path.exists(eval_output_dir):
            os.makedirs(eval_output_dir)
        
        eval_sampler = SequentialSampler(eval_dataset)
        eval_dataloader = DataLoader(eval_dataset,
                                     sampler=eval_sampler, 
                                     batch_size=args['eval_batch_size'],
                                     num_workers=4,
                                     pin_memory=True)
        
        print("***** EVALUATION *****")
        print("  Num examples = %d", len(eval_dataset))
        print("  Batch size = %d", args['eval_batch_size'])
        eval_loss = 0.0
        nb_eval_steps = 0
        self.model.eval()
        logits=[] 
        labels=[]
        for batch in eval_dataloader:
            inputs = batch[0].to(args['device'])        
            label=batch[1].to(args['device']) 
            with torch.no_grad():
                lm_loss,logit = self.model(inputs,label)
                eval_loss += lm_loss.mean().item()
                logits.append(logit.cpu().numpy())
                labels.append(label.cpu().numpy())
            nb_eval_steps += 1
        logits=np.concatenate(logits,0)
        labels=np.concatenate(labels,0)
        preds=logits.argmax(-1)
        eval_acc=np.mean(labels==preds)
        eval_loss = eval_loss / nb_eval_steps
        perplexity = torch.tensor(eval_loss)
                
        result = {
            "eval_loss": float(perplexity),
            "eval_acc":round(eval_acc,4),
        }
        return result
    
def test(args, model, tokenizer):
    eval_dataset = ExploitsDataset(tokenizer, args, args['test_data_file'])
    eval_sampler = SequentialSampler(eval_dataset)
    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args['eval_batch_size'])
    print("***** TESTING *****")
    print("  Num examples = %d", len(eval_dataset))
    print("  Batch size = %d", args['eval_batch_size'])
    eval_loss = 0.0
    nb_eval_steps = 0
    model.eval()
    logits=[]   
    labels=[]
    for batch in tqdm(eval_dataloader, total=len(eval_dataloader)):
        inputs = batch[0].to(args['device'])        
        label = batch[1].to(args['device']) 
        with torch.no_grad():
            lm_loss,logit = model(inputs,label)
            logits.append(logit.cpu().numpy())
            labels.append(label.cpu().numpy())
    logits = np.concatenate(logits, 0)
    labels = np.concatenate(labels, 0)
    preds = logits.argmax(-1)

    print("METRICS:\n", metrics.classification_report(labels, preds))
    with open(os.path.join(args['output_dir'],"predictions.txt"),'w', encoding="utf-8") as f:
        f.write("METRICS:\n" + str(metrics.classification_report(labels, preds)))
        f.write('target\tpredicted\n')
        for example, pred in zip(labels, preds):
            if pred:
                f.write(str(example) + '\t1\n')
            else:
                f.write(str(example) + '\t0\n')
    
    classification_rep = metrics.classification_report(labels, preds, output_dict=True)
    metrics_list = [{int(k): v} for k, v in classification_rep.items() if k.isdigit()]

    result_dict = {
        'metrics': metrics_list,
        'target': [int(example) for example in labels],
        'predicted': [int(pred) for pred in preds]
    }

    output_dir = args['output_dir']
    file_path = os.path.join(output_dir, "predictions.json")

    with open(file_path, 'w', encoding="utf-8") as json_file:
        json.dump(result_dict, json_file, ensure_ascii=False, indent=4)

        

if __name__=="__main__":
    with open(f"./config.yaml", 'r', encoding="utf-8") as r:
        args = yaml.safe_load(r)
    
    if args['do_train']:
        trainer = ExploitsModelTrainer(args=args, num_labels=args['num_labels'])
        trainer.train(args=args)
    
    if args['do_test']:
        config = RobertaConfig.from_pretrained(args['model_name_or_path'])
        config.num_labels = args['num_labels']
        
        tokenizer = RobertaTokenizer.from_pretrained(args['tokenizer_name'])
        model = RobertaForSequenceClassification.from_pretrained(args['model_name_or_path'], config=config)
        model = ExploitsModel(model, config, tokenizer, args)
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        args['device'] = device
        model.to(device)
        
        checkpoint_prefix = 'checkpoint-best-acc/model.bin'
        output_dir = os.path.join(args['output_dir'], '{}'.format(checkpoint_prefix))
        model.load_state_dict(torch.load(output_dir))
        model.to(args['device'])
        test(args, model, tokenizer)